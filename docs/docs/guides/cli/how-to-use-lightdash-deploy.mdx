import PersonalAccessToken from './assets/personal-access-token.png';
import GithubSecrets from './assets/github-secrets.jpg';
import NewWorkflowExistingActions from './assets/new-workflow-existing-actions.jpg';
import GithubRun from './assets/github-run.png';

# Sync your changes with Lightdash deploy

## `lightdash deploy` syncs the changes in your dbt project to Lightdash

If you've made some changes to your dbt project and you'd like to make them available in your Lightdash project, you can easily do this using the `lightdash deploy` command in the Lightdash CLI tool.

```shell
git checkout main # checkout main or master - or whatever your production branch name is where you've merged your changes
git pull
lightdash deploy # --target prod. If you use developer profiles in your dbt project, you might need this flag. See below.
```

This will deploy the changes in your dbt project to the Lightdash project you set up on your CLI tool earlier.

:::info

**Note:** Lightdash's deploy command will deploy using your **default dbt profile** unless you specify to use a different target. For example, if you've set up a developer profile where it targets a dev dataset (like `dbt_khindson.my_model_names`), then you'll need to pass the production target in your `lightdash deploy` command. Something like: `lightdash deploy --profile prod`.

:::

And voil√†! Once it's completed click the URL to head straight to your project where your changes will be ready to be explored.

## Automatically deploy your changes to Lightdash using a GitHub action

If you've connected Lightdash to GitHub, you can setup a `github action` and get Lightdash to deploy your project automatically. This is the easiest way to keep Lightdash in sync with your changes in dbt.

### Step 1: add the credentials to Github secrets

We are going to add some secrets and config to GitHub actions, but you don't want those to be public , so the best way to do this is to add them as secrets on Github

Go to your repo, click on `Settings` , on the left sidebar, click on `Secrets` under `Security`. Now click on the `New repository secret`

  <img src={GithubSecrets} width="940" height="681" style={{display: "block", margin: "0 auto 20px auto"}}/>

We need to add the following secrets:

### `LIGHTDASH_API_KEY`

Create a new personal access token, by going to `Settings` > `Personal Access Tokens`. This is the token you'll put in for `LIGHTDASH_API_KEY`.  

  <img src={PersonalAccessToken} width="1304" height="517" style={{display: "block", margin: "0 auto 20px auto"}}/>

### `LIGHTDASH_PROJECT`

The UUID for your project. For example, if your URL looks like `https://eu1.lightdash.cloud/projects/3538ab33-dc90-aabb-bc00-e50bba3a5f69/tables`, then `3538ab33-dc90-45f0-aabb-e50bba3a5f69` is your `LIGHTDASH_PROJECT`  

### `LIGHTDASH_URL`

This is either `https://eu1.lightdash.cloud` or `https://app.lightdash.cloud` (check the URL to your Lightdash project)

### `DBT_PROFILES`

Click on your data warehouse to get a profiles.yml file template. Fill out this template, and this is your `DBT_PROFILES` secret.

You might be able to copy a bunch of the information from your local `profiles.yml` file. You can see what's in there by typing `cat ~/.dbt/profiles.yml` in your terminal.

<details>
  <summary>BigQuery</summary>
  
  [Service Account JSON](https://docs.getdbt.com/reference/warehouse-profiles/bigquery-profile#service-account-json):

  ```yaml
  my-bigquery-db:
    target: dev
    outputs:
      dev:
        type: bigquery
        method: service-account-json
        project: [GCP project id]
        dataset: [the name of your dbt dataset]
        threads: [1 or more]

        # These fields come from the service account json keyfile
        keyfile_json:
          type: xxx
          project_id: xxx
          private_key_id: xxx
          private_key: xxx
          client_email: xxx
          client_id: xxx
          auth_uri: xxx
          token_uri: xxx
          auth_provider_x509_cert_url: xxx
          client_x509_cert_url: xxx
    ```
</details>

<details>
  <summary>Postgres</summary>
  
  [Postgres profile configuration](https://docs.getdbt.com/reference/warehouse-profiles/postgres-profile#profile-configuration):

  ```yaml
  company-name:
    target: dev
    outputs:
      dev:
        type: postgres
        host: [hostname]
        user: [username]
        password: [password]
        port: [port]
        dbname: [database name]
        schema: [dbt schema]
        threads: [1 or more]
        keepalives_idle: 0
        connect_timeout: 10
        retries: 1  
    ```
</details>

<details>
  <summary>Redshift</summary>
  
  [Redshift password-based authentication](https://docs.getdbt.com/reference/warehouse-profiles/redshift-profile#password-based-authentication):

  ```yaml
  company-name:
    target: dev
    outputs:
      dev:
        type: redshift
        host: [hostname.region.redshift.amazonaws.com]
        user: [username]
        password: [password]
        port: 5439
        dbname: analytics
        schema: analytics
        threads: 4
        keepalives_idle: 240 
        connect_timeout: 10 
        ra3_node: true # enables cross-database sources
    ```
</details>

<details>
  <summary>Snowflake</summary>
  
  [User / Password authentication](https://docs.getdbt.com/reference/warehouse-profiles/snowflake-profile#user--password-authentication)

  ```yaml
  my-snowflake-db:
    target: dev
    outputs:
      dev:
        type: snowflake
        account: [account id]

        # User/password auth
        user: [username]
        password: [password]

        role: [user role]
        database: [database name]
        warehouse: [warehouse name]
        schema: [dbt schema]
        threads: [1 or more]
        client_session_keep_alive: False
        query_tag: [anything]
  ```
</details>

<details>
  <summary>DataBricks</summary>
  
  [Set up a DataBricks target](https://docs.getdbt.com/reference/warehouse-profiles/bigquery-profile#service-account-json):

  ```yaml
  your_profile_name:
   target: dev
   outputs:
      dev:
        type: databricks
        catalog: [optional catalog name, if you are using Unity Catalog, only available in dbt-databricks>=1.1.1]
        schema: [schema name]
        host: [yourorg.databrickshost.com]
        http_path: [/sql/your/http/path]
        token: [dapiXXXXXXXXXXXXXXXXXXXXXXX] # Personal Access Token (PAT)
        threads: [1 or more]
    ```
</details>

### Step 2: Create action.yml workflow in Github

Go to your repo, click on `Actions` menu.

If you don't have any GitHub actions, you'll just need to click on `Configure`

![Github actions page](./assets/github-actions.png)

If you have some GitHub actions in your repo already, click on `New workflow`, then select `setup a workflow yourself`.

<img src={NewWorkflowExistingActions} width="952" height="203" style={{display: "block", margin: "0 auto 20px auto"}}/>

Now copy [this file](https://github.com/lightdash/cli-actions/blob/main/action.yml) from our [cli-actions](https://github.com/lightdash/cli-actions) repo.

Give it a nice name like `deploy-lightdash.yml`

And commit this to your repo by clicking on `Start commit`.

::: info

This GitHub action will deploy using your **`prod` dbt profile** by default.

If you don't want to use the `prod` profile by default, you'll need to replace this line in the `action.yml` file:

```shell
run: lightdash deploy --project-dir . --profiles-dir . --profile prod || lightdash deploy --project-dir . --profiles-dir .
```

With this (and update `my_profile_name` with the profile name you want to use):
```shell
run: lightdash deploy --project-dir . --profiles-dir . --profile my_profile_name
```

:::

### You're done!

Everytime you make a change to your repo, on the `main` branch, it will automatically deploy your new config into your Lightdash projects

You can see the log on the `Github actions` page

<img src={GithubRun} width="970" height="739" style={{display: "block", margin: "0 auto 20px auto"}}/>
